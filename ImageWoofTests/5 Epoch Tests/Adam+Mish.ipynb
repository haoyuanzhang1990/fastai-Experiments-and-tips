{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing SOTA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_z2nIOR_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqkabKYDSKAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMAGEWOOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SalWyCjuSyte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (ImageList.from_folder(path).split_by_folder(valid='val')\n",
        "            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=128)\n",
        "            .databunch(bs=64, num_workers=2)\n",
        "            .presize(128, scale=(0.35,1))\n",
        "            .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFV87w1xdvDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# RAdam + LARS\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                radam_norm = p_data_fp32.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-radam_step * trust_ratio, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-radam_step * trust_ratio, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQi9SAlxdyMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n",
        "     ralamb = Ralamb(params, *args, **kwargs)\n",
        "     return Lookahead(ralamb, alpha, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7AE5fm-TI6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func=partial(Over9000, betas = (0.9,0.99), eps=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGLvGNzOXK5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.distributed import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0H8gODXekJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIPV6cSAeH-C",
        "colab_type": "code",
        "outputId": "d1226839-de70-49f3-fcfc-5089cdb16ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch,math,sys\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from functools import partial\n",
        "#from ...torch_core import Module\n",
        "from fastai.torch_core import Module\n",
        "\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Mish activation loaded...\")\n",
        "\n",
        "    def forward(self, x): \n",
        "        \n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish()#nn.ReLU(inplace=True)\n",
        "\n",
        "__all__ = ['MXResNet', 'mxresnet18', 'mxresnet34', 'mxresnet50', 'mxresnet101', 'mxresnet152']\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish() #nn.ReLU(inplace=True)\n",
        "\n",
        "class Flatten(Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "def noop(x): return x\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        # TODO: check whether act=True works better\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "def filt_sz(recep): return min(64, 2**math.floor(math.log2(recep*0.75)))\n",
        "\n",
        "class MXResNet(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n",
        "        stem = []\n",
        "        sizes = [c_in,32,64,64]  #modified per Grankin\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n",
        "            #nf = filt_sz(c_in*9)\n",
        "            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n",
        "            #c_in = nf\n",
        "\n",
        "        block_szs = [64//expansion,64,128,256,512]\n",
        "        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        super().__init__(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *blocks,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(block_szs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(self)\n",
        "\n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(blocks)])\n",
        "\n",
        "def mxresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n",
        "    model = MXResNet(expansion, n_layers, **kwargs)\n",
        "    if pretrained: \n",
        "        #model.load_state_dict(model_zoo.load_url(model_urls[name]))\n",
        "        print(\"No pretrained yet for MXResNet\")\n",
        "    return model\n",
        "\n",
        "me = sys.modules[__name__]\n",
        "for n,e,l in [\n",
        "    [ 18 , 1, [2,2,2 ,2] ],\n",
        "    [ 34 , 1, [3,4,6 ,3] ],\n",
        "    [ 50 , 4, [3,4,6 ,3] ],\n",
        "    [ 101, 4, [3,4,23,3] ],\n",
        "    [ 152, 4, [3,8,36,3] ],\n",
        "]:\n",
        "    name = f'mxresnet{n}'\n",
        "    setattr(me, name, partial(mxresnet, expansion=e, n_layers=l, name=name))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mish activation loaded...\n",
            "Mish activation loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3kefDgEeKb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
        "#https://arxiv.org/abs/1908.08681v1\n",
        "#implemented for PyTorch / FastAI by lessw2020 \n",
        "#github: https://github.com/lessw2020/mish\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemWTu8NeWfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools as it\n",
        "from torch.optim import Optimizer, Adam\n",
        "\n",
        "class Lookahead(Optimizer):\n",
        "    def __init__(self, base_optimizer,alpha=0.5, k=6):\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        self.optimizer = base_optimizer\n",
        "        self.param_groups = self.optimizer.param_groups\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        for group in self.param_groups:\n",
        "            group[\"step_counter\"] = 0\n",
        "        self.slow_weights = [[p.clone().detach() for p in group['params']]\n",
        "                                for group in self.param_groups]\n",
        "\n",
        "        for w in it.chain(*self.slow_weights):\n",
        "            w.requires_grad = False\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "        loss = self.optimizer.step()\n",
        "        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n",
        "            group['step_counter'] += 1\n",
        "            if group['step_counter'] % self.k != 0:\n",
        "                continue\n",
        "            for p,q in zip(group['params'],slow_weights):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                q.data.add_(self.alpha,p.data - q.data)\n",
        "                p.data.copy_(q.data)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-NkvL2Sdyv",
        "colab_type": "code",
        "outputId": "09411745-c03d-490b-e4b6-9411f7d240e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "res = []\n",
        "num_epoch=5\n",
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(5, max_lr=3e-3)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.083100</td>\n",
              "      <td>2.444148</td>\n",
              "      <td>0.272000</td>\n",
              "      <td>0.776000</td>\n",
              "      <td>02:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.822745</td>\n",
              "      <td>2.014540</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.620592</td>\n",
              "      <td>1.600764</td>\n",
              "      <td>0.562000</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.382782</td>\n",
              "      <td>1.346453</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.254521</td>\n",
              "      <td>1.226960</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZyW388bkDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJX7Ylxblox",
        "colab_type": "code",
        "outputId": "65fc65f6-c50c-44fe-ba48-629c25932cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(5, max_lr=3e-3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.045608</td>\n",
              "      <td>2.111278</td>\n",
              "      <td>0.256000</td>\n",
              "      <td>0.786000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.847058</td>\n",
              "      <td>1.905652</td>\n",
              "      <td>0.358000</td>\n",
              "      <td>0.858000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.582536</td>\n",
              "      <td>1.541181</td>\n",
              "      <td>0.534000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.373685</td>\n",
              "      <td>1.300914</td>\n",
              "      <td>0.676000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.237160</td>\n",
              "      <td>1.199814</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ER6N0lcbmZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cmH0cLbnPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f2539b06-6fc5-4a1b-cc9d-477b610c6b6c"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(5, max_lr=3e-3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.068114</td>\n",
              "      <td>2.156122</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.881892</td>\n",
              "      <td>2.394030</td>\n",
              "      <td>0.314000</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.649277</td>\n",
              "      <td>1.834863</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.872000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.450145</td>\n",
              "      <td>1.401591</td>\n",
              "      <td>0.584000</td>\n",
              "      <td>0.944000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.313125</td>\n",
              "      <td>1.265555</td>\n",
              "      <td>0.674000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHJVXRQboCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfuhPs_dboyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dd6cba4c-f658-41f4-dd98-5d13ec475dac"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(5, max_lr=3e-3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.071420</td>\n",
              "      <td>2.363792</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>02:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.821010</td>\n",
              "      <td>1.889182</td>\n",
              "      <td>0.366000</td>\n",
              "      <td>0.866000</td>\n",
              "      <td>02:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.608572</td>\n",
              "      <td>1.539322</td>\n",
              "      <td>0.532000</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.385292</td>\n",
              "      <td>1.284918</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.265220</td>\n",
              "      <td>1.195431</td>\n",
              "      <td>0.734000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zluKwmebpWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTtJywE8bq5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cc089a81-363c-4438-c298-efeabe9d5262"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(5, max_lr=3e-3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.070423</td>\n",
              "      <td>2.743564</td>\n",
              "      <td>0.256000</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.841229</td>\n",
              "      <td>1.933486</td>\n",
              "      <td>0.376000</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.597929</td>\n",
              "      <td>1.945745</td>\n",
              "      <td>0.454000</td>\n",
              "      <td>0.848000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.411162</td>\n",
              "      <td>1.290254</td>\n",
              "      <td>0.652000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.277606</td>\n",
              "      <td>1.209214</td>\n",
              "      <td>0.722000</td>\n",
              "      <td>0.958000</td>\n",
              "      <td>02:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkPOpr9Kbrf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnABPBXUiwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c6d6ce9-7f75-4ccf-8d96-40ea5de638f8"
      },
      "source": [
        "np.mean(res)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.70439994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_vjMWEiL7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f08ea6c-d3b9-4aa3-bbcc-6899b626250c"
      },
      "source": [
        "np.std(res)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022535304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hArOffsgiNP-",
        "colab_type": "code",
        "outputId": "62f22658-25e8-4b5a-c0ed-a179cbe48338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(0.684, dtype=float32),\n",
              " array(0.708, dtype=float32),\n",
              " array(0.674, dtype=float32),\n",
              " array(0.734, dtype=float32),\n",
              " array(0.722, dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OU10gtbiumN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}