{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProperTest.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfCN2QLKlrHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "979b765c-d104-46fd-9710-826756f9bb4b"
      },
      "source": [
        "!git clone https://github.com/lessw2020/mish.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mish'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 8), reused 10 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FweRsNG-mXgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6388f54f-cab8-4d0c-bfb5-e95d011a09ce"
      },
      "source": [
        "!git clone https://github.com/mgrankin/over9000.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'over9000'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 71 (delta 37), reused 42 (delta 19), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_p13UODlz_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec872522-5835-45d9-a45e-8455a75ddd3a"
      },
      "source": [
        "%cd mish"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdBjArECn0Yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa9ae37e-65b4-4bfb-a731-2281e1e651d0"
      },
      "source": [
        "from mxresnet import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mish activation loaded...\n",
            "Mish activation loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEBecFdOoHpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import itertools as it\n",
        "\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step_size = 1 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step_size\n",
        "\n",
        "                update = torch.zeros_like(p_data_fp32)\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    update.addcdiv_(radam_step_size, exp_avg, denom)\n",
        "                else:\n",
        "                    update.add_(radam_step_size, exp_avg)\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    update.add_(group['weight_decay'], p_data_fp32)\n",
        "\n",
        "                radam_norm = update.pow(2).sum().sqrt()\n",
        "                weight_norm = p.data.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                trust_ratio = max(0, min(10, trust_ratio))\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                p_data_fp32.add_(-update * trust_ratio * group['lr'])\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7gbBokWmBkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHeXN8wUmQDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMAGEWOOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_eXff-kmRZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (ImageList.from_folder(path).split_by_folder(valid='val')\n",
        "            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=128)\n",
        "            .databunch(bs=64, num_workers=2)\n",
        "            .presize(128, scale=(0.35,1))\n",
        "            .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miE82HL5mUO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func=partial(Ralamb, betas = (0.9,0.99), eps=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1-pWlf7mc2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.distributed import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuoWTk-wmdfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku7zASqwmebx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = []\n",
        "num_epoch=5\n",
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*5*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*5 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n",
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eLS4NYRq2vW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f10df1a0-5b5b-4527-9dcf-664470c775eb"
      },
      "source": [
        "print(res)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array(0.532, dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDenE8xjmh_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*5*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*5 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n",
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq7pGbJvnUI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*5*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*5 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n",
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQKa41nWnUe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*5*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*5 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n",
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQUjfI0TnVF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*5*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*5 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n",
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk6QoC3onVcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}