{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing SOTA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_z2nIOR_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqkabKYDSKAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMAGEWOOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SalWyCjuSyte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (ImageList.from_folder(path).split_by_folder(valid='val')\n",
        "            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=128)\n",
        "            .databunch(bs=64, num_workers=2)\n",
        "            .presize(128, scale=(0.35,1))\n",
        "            .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFV87w1xdvDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# RAdam + LARS\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                radam_norm = p_data_fp32.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-radam_step * trust_ratio, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-radam_step * trust_ratio, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQi9SAlxdyMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n",
        "     ralamb = Ralamb(params, *args, **kwargs)\n",
        "     return Lookahead(ralamb, alpha, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7AE5fm-TI6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func=partial(Over9000, betas = (0.9,0.99), eps=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGLvGNzOXK5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.distributed import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0H8gODXekJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIPV6cSAeH-C",
        "colab_type": "code",
        "outputId": "2f04edad-6c4a-4fc1-9c2c-95da8e290801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch,math,sys\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from functools import partial\n",
        "#from ...torch_core import Module\n",
        "from fastai.torch_core import Module\n",
        "\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Mish activation loaded...\")\n",
        "\n",
        "    def forward(self, x): \n",
        "        \n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish()#nn.ReLU(inplace=True)\n",
        "\n",
        "__all__ = ['MXResNet', 'mxresnet18', 'mxresnet34', 'mxresnet50', 'mxresnet101', 'mxresnet152']\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish() #nn.ReLU(inplace=True)\n",
        "\n",
        "class Flatten(Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "def noop(x): return x\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        # TODO: check whether act=True works better\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "def filt_sz(recep): return min(64, 2**math.floor(math.log2(recep*0.75)))\n",
        "\n",
        "class MXResNet(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n",
        "        stem = []\n",
        "        sizes = [c_in,32,64,64]  #modified per Grankin\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n",
        "            #nf = filt_sz(c_in*9)\n",
        "            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n",
        "            #c_in = nf\n",
        "\n",
        "        block_szs = [64//expansion,64,128,256,512]\n",
        "        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        super().__init__(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *blocks,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(block_szs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(self)\n",
        "\n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(blocks)])\n",
        "\n",
        "def mxresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n",
        "    model = MXResNet(expansion, n_layers, **kwargs)\n",
        "    if pretrained: \n",
        "        #model.load_state_dict(model_zoo.load_url(model_urls[name]))\n",
        "        print(\"No pretrained yet for MXResNet\")\n",
        "    return model\n",
        "\n",
        "me = sys.modules[__name__]\n",
        "for n,e,l in [\n",
        "    [ 18 , 1, [2,2,2 ,2] ],\n",
        "    [ 34 , 1, [3,4,6 ,3] ],\n",
        "    [ 50 , 4, [3,4,6 ,3] ],\n",
        "    [ 101, 4, [3,4,23,3] ],\n",
        "    [ 152, 4, [3,8,36,3] ],\n",
        "]:\n",
        "    name = f'mxresnet{n}'\n",
        "    setattr(me, name, partial(mxresnet, expansion=e, n_layers=l, name=name))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mish activation loaded...\n",
            "Mish activation loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3kefDgEeKb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
        "#https://arxiv.org/abs/1908.08681v1\n",
        "#implemented for PyTorch / FastAI by lessw2020 \n",
        "#github: https://github.com/lessw2020/mish\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemWTu8NeWfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools as it\n",
        "from torch.optim import Optimizer, Adam\n",
        "\n",
        "class Lookahead(Optimizer):\n",
        "    def __init__(self, base_optimizer,alpha=0.5, k=6):\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        self.optimizer = base_optimizer\n",
        "        self.param_groups = self.optimizer.param_groups\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        for group in self.param_groups:\n",
        "            group[\"step_counter\"] = 0\n",
        "        self.slow_weights = [[p.clone().detach() for p in group['params']]\n",
        "                                for group in self.param_groups]\n",
        "\n",
        "        for w in it.chain(*self.slow_weights):\n",
        "            w.requires_grad = False\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "        loss = self.optimizer.step()\n",
        "        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n",
        "            group['step_counter'] += 1\n",
        "            if group['step_counter'] % self.k != 0:\n",
        "                continue\n",
        "            for p,q in zip(group['params'],slow_weights):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                q.data.add_(self.alpha,p.data - q.data)\n",
        "                p.data.copy_(q.data)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-NkvL2Sdyv",
        "colab_type": "code",
        "outputId": "64eb971a-c0b6-4df4-d3cc-49fb5b0e8bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "res = []\n",
        "num_epoch=20\n",
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.023704</td>\n",
              "      <td>2.017615</td>\n",
              "      <td>0.382000</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>02:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.770728</td>\n",
              "      <td>1.832983</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.610263</td>\n",
              "      <td>1.530681</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>0.918000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.463128</td>\n",
              "      <td>1.397101</td>\n",
              "      <td>0.612000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.357713</td>\n",
              "      <td>1.426165</td>\n",
              "      <td>0.604000</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.272313</td>\n",
              "      <td>1.200831</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.189963</td>\n",
              "      <td>1.251887</td>\n",
              "      <td>0.692000</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.142661</td>\n",
              "      <td>1.398860</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.098895</td>\n",
              "      <td>1.058892</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.059684</td>\n",
              "      <td>1.146692</td>\n",
              "      <td>0.732000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.040095</td>\n",
              "      <td>1.146667</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.015700</td>\n",
              "      <td>1.005448</td>\n",
              "      <td>0.788000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.984542</td>\n",
              "      <td>0.991588</td>\n",
              "      <td>0.792000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.969725</td>\n",
              "      <td>1.123209</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.928945</td>\n",
              "      <td>0.970567</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.888835</td>\n",
              "      <td>0.973487</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.828884</td>\n",
              "      <td>0.921278</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.789631</td>\n",
              "      <td>0.899115</td>\n",
              "      <td>0.836000</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.741616</td>\n",
              "      <td>0.874739</td>\n",
              "      <td>0.848000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.716236</td>\n",
              "      <td>0.862422</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZyW388bkDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJX7Ylxblox",
        "colab_type": "code",
        "outputId": "e4a66aa5-2a3b-4450-8cea-b5dcf48067fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.059485</td>\n",
              "      <td>2.109135</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.804411</td>\n",
              "      <td>3.343117</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.620854</td>\n",
              "      <td>1.460293</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.463698</td>\n",
              "      <td>1.473934</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.914000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.366542</td>\n",
              "      <td>1.385709</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.257933</td>\n",
              "      <td>1.177579</td>\n",
              "      <td>0.726000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.213137</td>\n",
              "      <td>1.279688</td>\n",
              "      <td>0.658000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.158054</td>\n",
              "      <td>1.382020</td>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.103974</td>\n",
              "      <td>1.103710</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.080370</td>\n",
              "      <td>1.067681</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.036210</td>\n",
              "      <td>1.374025</td>\n",
              "      <td>0.648000</td>\n",
              "      <td>0.948000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.015756</td>\n",
              "      <td>1.014819</td>\n",
              "      <td>0.802000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.994601</td>\n",
              "      <td>0.995067</td>\n",
              "      <td>0.796000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.947390</td>\n",
              "      <td>1.087738</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.938694</td>\n",
              "      <td>0.925677</td>\n",
              "      <td>0.836000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.889304</td>\n",
              "      <td>0.977494</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.839468</td>\n",
              "      <td>0.914873</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.774645</td>\n",
              "      <td>0.878196</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.731261</td>\n",
              "      <td>0.865355</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.711744</td>\n",
              "      <td>0.866791</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ER6N0lcbmZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cmH0cLbnPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "68153e79-6c28-44a7-98d9-327fa97bd91f"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.081718</td>\n",
              "      <td>3.171293</td>\n",
              "      <td>0.142000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.800678</td>\n",
              "      <td>2.803348</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.655875</td>\n",
              "      <td>1.480860</td>\n",
              "      <td>0.566000</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.481250</td>\n",
              "      <td>1.415093</td>\n",
              "      <td>0.592000</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.381016</td>\n",
              "      <td>1.551865</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.285699</td>\n",
              "      <td>1.203709</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.221502</td>\n",
              "      <td>1.224392</td>\n",
              "      <td>0.712000</td>\n",
              "      <td>0.958000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.161773</td>\n",
              "      <td>1.528642</td>\n",
              "      <td>0.572000</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.119028</td>\n",
              "      <td>1.093334</td>\n",
              "      <td>0.764000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.057888</td>\n",
              "      <td>1.106549</td>\n",
              "      <td>0.748000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.044107</td>\n",
              "      <td>1.260744</td>\n",
              "      <td>0.696000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.012625</td>\n",
              "      <td>1.050991</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.996398</td>\n",
              "      <td>0.994732</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.950585</td>\n",
              "      <td>1.064387</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.940796</td>\n",
              "      <td>0.924626</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.899792</td>\n",
              "      <td>0.994902</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.841143</td>\n",
              "      <td>0.906859</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.774876</td>\n",
              "      <td>0.863640</td>\n",
              "      <td>0.848000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.744559</td>\n",
              "      <td>0.831774</td>\n",
              "      <td>0.854000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.712139</td>\n",
              "      <td>0.837711</td>\n",
              "      <td>0.854000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHJVXRQboCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfuhPs_dboyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "897be268-fc49-492a-8469-c87aaeeba674"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.055410</td>\n",
              "      <td>1.986028</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.810345</td>\n",
              "      <td>2.042499</td>\n",
              "      <td>0.316000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.642179</td>\n",
              "      <td>1.602980</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.474641</td>\n",
              "      <td>1.607989</td>\n",
              "      <td>0.502000</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.349392</td>\n",
              "      <td>1.691946</td>\n",
              "      <td>0.526000</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.260427</td>\n",
              "      <td>1.255649</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.208528</td>\n",
              "      <td>1.331222</td>\n",
              "      <td>0.638000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.147038</td>\n",
              "      <td>1.274948</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.112309</td>\n",
              "      <td>1.022265</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.078243</td>\n",
              "      <td>1.126799</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.041945</td>\n",
              "      <td>1.193882</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.017157</td>\n",
              "      <td>1.025308</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.968461</td>\n",
              "      <td>1.047387</td>\n",
              "      <td>0.762000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.977385</td>\n",
              "      <td>1.030996</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.937259</td>\n",
              "      <td>0.943642</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.902526</td>\n",
              "      <td>0.983232</td>\n",
              "      <td>0.786000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.839886</td>\n",
              "      <td>0.932409</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.787143</td>\n",
              "      <td>0.887322</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.742777</td>\n",
              "      <td>0.861693</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.721604</td>\n",
              "      <td>0.857929</td>\n",
              "      <td>0.836000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zluKwmebpWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTtJywE8bq5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "92d512c9-84b9-4486-da89-42d57207ee62"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.021558</td>\n",
              "      <td>2.115930</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.745855</td>\n",
              "      <td>2.678405</td>\n",
              "      <td>0.262000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.588238</td>\n",
              "      <td>1.493388</td>\n",
              "      <td>0.562000</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.447646</td>\n",
              "      <td>1.649811</td>\n",
              "      <td>0.536000</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.338014</td>\n",
              "      <td>1.447098</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.258696</td>\n",
              "      <td>1.189628</td>\n",
              "      <td>0.724000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.187186</td>\n",
              "      <td>1.490146</td>\n",
              "      <td>0.612000</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.129792</td>\n",
              "      <td>1.245394</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.119588</td>\n",
              "      <td>1.040790</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.072259</td>\n",
              "      <td>1.108689</td>\n",
              "      <td>0.736000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.034730</td>\n",
              "      <td>1.218046</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.020045</td>\n",
              "      <td>1.007089</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.983677</td>\n",
              "      <td>0.983791</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.961057</td>\n",
              "      <td>1.251845</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.927248</td>\n",
              "      <td>0.940023</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.891310</td>\n",
              "      <td>0.935262</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.836978</td>\n",
              "      <td>0.925503</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.769195</td>\n",
              "      <td>0.862272</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.726906</td>\n",
              "      <td>0.857751</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.705941</td>\n",
              "      <td>0.852663</td>\n",
              "      <td>0.848000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkPOpr9Kbrf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnABPBXUiwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07640eb2-5755-42d8-d19a-5cbd7f2c7329"
      },
      "source": [
        "np.mean(res)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84639996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_vjMWEiL7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6f2027d-8aaf-4ef3-8f37-c384d2ad1565"
      },
      "source": [
        "np.std(res)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006621162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hArOffsgiNP-",
        "colab_type": "code",
        "outputId": "751ca010-d3f2-495e-9dd7-553755974642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(0.852, dtype=float32),\n",
              " array(0.842, dtype=float32),\n",
              " array(0.854, dtype=float32),\n",
              " array(0.836, dtype=float32),\n",
              " array(0.848, dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OU10gtbiumN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}