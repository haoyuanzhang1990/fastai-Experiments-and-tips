{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing SOTA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_z2nIOR_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqkabKYDSKAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMAGEWOOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SalWyCjuSyte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (ImageList.from_folder(path).split_by_folder(valid='val')\n",
        "            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=128)\n",
        "            .databunch(bs=64, num_workers=2)\n",
        "            .presize(128, scale=(0.35,1))\n",
        "            .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFV87w1xdvDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# RAdam + LARS\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                radam_norm = p_data_fp32.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-radam_step * trust_ratio, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-radam_step * trust_ratio, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQi9SAlxdyMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n",
        "     ralamb = Ralamb(params, *args, **kwargs)\n",
        "     return Lookahead(ralamb, alpha, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7AE5fm-TI6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func=partial(Over9000, betas = (0.9,0.99), eps=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGLvGNzOXK5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.distributed import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0H8gODXekJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIPV6cSAeH-C",
        "colab_type": "code",
        "outputId": "17cdcf04-a763-42d5-eabb-48054de79c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch,math,sys\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from functools import partial\n",
        "#from ...torch_core import Module\n",
        "from fastai.torch_core import Module\n",
        "\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Mish activation loaded...\")\n",
        "\n",
        "    def forward(self, x): \n",
        "        \n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish()#nn.ReLU(inplace=True)\n",
        "\n",
        "__all__ = ['MXResNet', 'mxresnet18', 'mxresnet34', 'mxresnet50', 'mxresnet101', 'mxresnet152']\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish() #nn.ReLU(inplace=True)\n",
        "\n",
        "class Flatten(Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "def noop(x): return x\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        # TODO: check whether act=True works better\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "def filt_sz(recep): return min(64, 2**math.floor(math.log2(recep*0.75)))\n",
        "\n",
        "class MXResNet(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n",
        "        stem = []\n",
        "        sizes = [c_in,32,64,64]  #modified per Grankin\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n",
        "            #nf = filt_sz(c_in*9)\n",
        "            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n",
        "            #c_in = nf\n",
        "\n",
        "        block_szs = [64//expansion,64,128,256,512]\n",
        "        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        super().__init__(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *blocks,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(block_szs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(self)\n",
        "\n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(blocks)])\n",
        "\n",
        "def mxresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n",
        "    model = MXResNet(expansion, n_layers, **kwargs)\n",
        "    if pretrained: \n",
        "        #model.load_state_dict(model_zoo.load_url(model_urls[name]))\n",
        "        print(\"No pretrained yet for MXResNet\")\n",
        "    return model\n",
        "\n",
        "me = sys.modules[__name__]\n",
        "for n,e,l in [\n",
        "    [ 18 , 1, [2,2,2 ,2] ],\n",
        "    [ 34 , 1, [3,4,6 ,3] ],\n",
        "    [ 50 , 4, [3,4,6 ,3] ],\n",
        "    [ 101, 4, [3,4,23,3] ],\n",
        "    [ 152, 4, [3,8,36,3] ],\n",
        "]:\n",
        "    name = f'mxresnet{n}'\n",
        "    setattr(me, name, partial(mxresnet, expansion=e, n_layers=l, name=name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mish activation loaded...\n",
            "Mish activation loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3kefDgEeKb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
        "#https://arxiv.org/abs/1908.08681v1\n",
        "#implemented for PyTorch / FastAI by lessw2020 \n",
        "#github: https://github.com/lessw2020/mish\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemWTu8NeWfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools as it\n",
        "from torch.optim import Optimizer, Adam\n",
        "\n",
        "class Lookahead(Optimizer):\n",
        "    def __init__(self, base_optimizer,alpha=0.5, k=6):\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        self.optimizer = base_optimizer\n",
        "        self.param_groups = self.optimizer.param_groups\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        for group in self.param_groups:\n",
        "            group[\"step_counter\"] = 0\n",
        "        self.slow_weights = [[p.clone().detach() for p in group['params']]\n",
        "                                for group in self.param_groups]\n",
        "\n",
        "        for w in it.chain(*self.slow_weights):\n",
        "            w.requires_grad = False\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "        loss = self.optimizer.step()\n",
        "        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n",
        "            group['step_counter'] += 1\n",
        "            if group['step_counter'] % self.k != 0:\n",
        "                continue\n",
        "            for p,q in zip(group['params'],slow_weights):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                q.data.add_(self.alpha,p.data - q.data)\n",
        "                p.data.copy_(q.data)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-NkvL2Sdyv",
        "colab_type": "code",
        "outputId": "a8cb0a89-5df7-46bd-9ead-0dd6f5e81563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "res = []\n",
        "num_epoch=20\n",
        "learn = Learner(data, models.xresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.146302</td>\n",
              "      <td>2.223222</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.752000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.842076</td>\n",
              "      <td>2.114983</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.685652</td>\n",
              "      <td>1.592352</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.538648</td>\n",
              "      <td>1.827383</td>\n",
              "      <td>0.444000</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.456481</td>\n",
              "      <td>2.143965</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.347925</td>\n",
              "      <td>1.288381</td>\n",
              "      <td>0.644000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.287330</td>\n",
              "      <td>1.329307</td>\n",
              "      <td>0.622000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.212908</td>\n",
              "      <td>1.628311</td>\n",
              "      <td>0.524000</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.172403</td>\n",
              "      <td>1.094053</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.132418</td>\n",
              "      <td>1.180146</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.090664</td>\n",
              "      <td>1.267096</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.062480</td>\n",
              "      <td>1.054025</td>\n",
              "      <td>0.764000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.019180</td>\n",
              "      <td>1.080541</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.994388</td>\n",
              "      <td>1.215461</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.979961</td>\n",
              "      <td>0.984097</td>\n",
              "      <td>0.816000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.928257</td>\n",
              "      <td>1.024871</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.874144</td>\n",
              "      <td>1.011061</td>\n",
              "      <td>0.774000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.815945</td>\n",
              "      <td>0.921795</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.773710</td>\n",
              "      <td>0.898626</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.746996</td>\n",
              "      <td>0.892555</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZyW388bkDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJX7Ylxblox",
        "colab_type": "code",
        "outputId": "5a6e151a-17a1-4c73-9b52-508ba45d2e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "learn = Learner(data, models.xresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.147192</td>\n",
              "      <td>2.248813</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.774000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.884788</td>\n",
              "      <td>2.852487</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.756000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.703208</td>\n",
              "      <td>1.634853</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.556314</td>\n",
              "      <td>1.556094</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.451079</td>\n",
              "      <td>1.776497</td>\n",
              "      <td>0.472000</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.330307</td>\n",
              "      <td>1.257899</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.274105</td>\n",
              "      <td>1.281263</td>\n",
              "      <td>0.642000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.205010</td>\n",
              "      <td>1.348686</td>\n",
              "      <td>0.616000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.173257</td>\n",
              "      <td>1.111886</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.130309</td>\n",
              "      <td>1.118891</td>\n",
              "      <td>0.724000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.078640</td>\n",
              "      <td>1.336984</td>\n",
              "      <td>0.648000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.049341</td>\n",
              "      <td>1.025891</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.021863</td>\n",
              "      <td>1.037480</td>\n",
              "      <td>0.764000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.989030</td>\n",
              "      <td>1.173660</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.964673</td>\n",
              "      <td>0.955662</td>\n",
              "      <td>0.796000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.922591</td>\n",
              "      <td>0.961151</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.867764</td>\n",
              "      <td>0.949117</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.798742</td>\n",
              "      <td>0.907400</td>\n",
              "      <td>0.814000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.754478</td>\n",
              "      <td>0.876200</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.743712</td>\n",
              "      <td>0.858274</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ER6N0lcbmZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cmH0cLbnPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "e439a569-af6c-4247-dbff-556ec64d8c33"
      },
      "source": [
        "learn = Learner(data, models.xresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.114615</td>\n",
              "      <td>2.323089</td>\n",
              "      <td>0.254000</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.867955</td>\n",
              "      <td>1.952459</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.786000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.661879</td>\n",
              "      <td>1.598179</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.565409</td>\n",
              "      <td>1.740468</td>\n",
              "      <td>0.456000</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.451349</td>\n",
              "      <td>1.821241</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.358532</td>\n",
              "      <td>1.269572</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.287325</td>\n",
              "      <td>1.226601</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.218368</td>\n",
              "      <td>1.374674</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.178592</td>\n",
              "      <td>1.069834</td>\n",
              "      <td>0.752000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.118158</td>\n",
              "      <td>1.140674</td>\n",
              "      <td>0.736000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.094500</td>\n",
              "      <td>2.104849</td>\n",
              "      <td>0.448000</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.065432</td>\n",
              "      <td>1.021240</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.028005</td>\n",
              "      <td>1.058661</td>\n",
              "      <td>0.762000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.008719</td>\n",
              "      <td>1.240847</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.971821</td>\n",
              "      <td>1.028603</td>\n",
              "      <td>0.782000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.937431</td>\n",
              "      <td>1.043497</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.881369</td>\n",
              "      <td>0.959196</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.818497</td>\n",
              "      <td>0.921269</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.782762</td>\n",
              "      <td>0.877163</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.750198</td>\n",
              "      <td>0.875440</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHJVXRQboCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfuhPs_dboyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "1f687d4b-9af0-49c6-d706-f6f466997727"
      },
      "source": [
        "learn = Learner(data, models.xresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.210266</td>\n",
              "      <td>2.254127</td>\n",
              "      <td>0.262000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.861580</td>\n",
              "      <td>2.128787</td>\n",
              "      <td>0.328000</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.700174</td>\n",
              "      <td>1.567581</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.579693</td>\n",
              "      <td>1.799343</td>\n",
              "      <td>0.432000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.440089</td>\n",
              "      <td>1.878111</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>0.876000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.359647</td>\n",
              "      <td>1.322391</td>\n",
              "      <td>0.628000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.291270</td>\n",
              "      <td>1.447528</td>\n",
              "      <td>0.586000</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.240058</td>\n",
              "      <td>1.316909</td>\n",
              "      <td>0.658000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.194371</td>\n",
              "      <td>1.163841</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.127161</td>\n",
              "      <td>1.400065</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.944000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.088972</td>\n",
              "      <td>1.169882</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.044633</td>\n",
              "      <td>1.052134</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.019664</td>\n",
              "      <td>1.085047</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.996738</td>\n",
              "      <td>1.063403</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.999865</td>\n",
              "      <td>1.054866</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.942456</td>\n",
              "      <td>1.014094</td>\n",
              "      <td>0.772000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.884066</td>\n",
              "      <td>1.010231</td>\n",
              "      <td>0.792000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.814858</td>\n",
              "      <td>0.900081</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.781456</td>\n",
              "      <td>0.871922</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.747991</td>\n",
              "      <td>0.862534</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zluKwmebpWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTtJywE8bq5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "88137f58-001e-43c4-db68-8b337938056c"
      },
      "source": [
        "learn = Learner(data, models.xresnet50(c_out=10), wd=1e-2, opt_func=opt_func,\n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "n = len(learn.data.train_dl)\n",
        "anneal_start = int(n*20*0.7)\n",
        "phase0 = TrainingPhase(anneal_start).schedule_hp('lr', lr)\n",
        "phase1 = TrainingPhase(n*20 - anneal_start).schedule_hp('lr', lr, anneal=annealing_cos)\n",
        "phases = [phase0, phase1]\n",
        "sched = GeneralScheduler(learn, phases)\n",
        "learn.callbacks.append(sched)\n",
        "learn.fit(num_epoch)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.217478</td>\n",
              "      <td>2.041850</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.786000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.904245</td>\n",
              "      <td>2.071724</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.723249</td>\n",
              "      <td>1.616565</td>\n",
              "      <td>0.468000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.583716</td>\n",
              "      <td>1.627288</td>\n",
              "      <td>0.526000</td>\n",
              "      <td>0.918000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.479077</td>\n",
              "      <td>1.729208</td>\n",
              "      <td>0.464000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.377752</td>\n",
              "      <td>1.302867</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.319221</td>\n",
              "      <td>1.247340</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.242403</td>\n",
              "      <td>1.434739</td>\n",
              "      <td>0.636000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.205399</td>\n",
              "      <td>1.159465</td>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.148004</td>\n",
              "      <td>1.211858</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.115434</td>\n",
              "      <td>1.144604</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.096204</td>\n",
              "      <td>1.050603</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.048948</td>\n",
              "      <td>1.161947</td>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.009092</td>\n",
              "      <td>1.133577</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.004937</td>\n",
              "      <td>1.067870</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.944088</td>\n",
              "      <td>1.048670</td>\n",
              "      <td>0.772000</td>\n",
              "      <td>0.974000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.894394</td>\n",
              "      <td>0.997573</td>\n",
              "      <td>0.792000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.828801</td>\n",
              "      <td>0.932554</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.785758</td>\n",
              "      <td>0.920350</td>\n",
              "      <td>0.816000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.770983</td>\n",
              "      <td>0.917459</td>\n",
              "      <td>0.824000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkPOpr9Kbrf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnABPBXUiwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06bdf953-bcf1-45a0-98e4-397b45aac4ed"
      },
      "source": [
        "np.mean(res)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82559997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_vjMWEiL7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf03747f-f8c5-47aa-f6e8-8b9ab226c124"
      },
      "source": [
        "np.std(res)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0044541988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hArOffsgiNP-",
        "colab_type": "code",
        "outputId": "08c683dd-beef-498c-8cd3-7824c73e1bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(0.822, dtype=float32),\n",
              " array(0.834, dtype=float32),\n",
              " array(0.826, dtype=float32),\n",
              " array(0.822, dtype=float32),\n",
              " array(0.824, dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OU10gtbiumN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}