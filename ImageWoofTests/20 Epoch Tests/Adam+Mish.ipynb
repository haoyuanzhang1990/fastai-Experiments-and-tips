{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing SOTA.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_z2nIOR_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqkabKYDSKAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMAGEWOOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SalWyCjuSyte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (ImageList.from_folder(path).split_by_folder(valid='val')\n",
        "            .label_from_folder().transform(([flip_lr(p=0.5)], []), size=128)\n",
        "            .databunch(bs=64, num_workers=2)\n",
        "            .presize(128, scale=(0.35,1))\n",
        "            .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFV87w1xdvDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# RAdam + LARS\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                radam_norm = p_data_fp32.pow(2).sum().sqrt()\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-radam_step * trust_ratio, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-radam_step * trust_ratio, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQi9SAlxdyMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n",
        "     ralamb = Ralamb(params, *args, **kwargs)\n",
        "     return Lookahead(ralamb, alpha, k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7AE5fm-TI6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func=partial(Over9000, betas = (0.9,0.99), eps=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGLvGNzOXK5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.distributed import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0H8gODXekJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIPV6cSAeH-C",
        "colab_type": "code",
        "outputId": "83e45864-5c95-485a-fc92-dc6d3c116f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch,math,sys\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from functools import partial\n",
        "#from ...torch_core import Module\n",
        "from fastai.torch_core import Module\n",
        "\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Mish activation loaded...\")\n",
        "\n",
        "    def forward(self, x): \n",
        "        \n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish()#nn.ReLU(inplace=True)\n",
        "\n",
        "__all__ = ['MXResNet', 'mxresnet18', 'mxresnet34', 'mxresnet50', 'mxresnet101', 'mxresnet152']\n",
        "\n",
        "# or: ELU+init (a=0.54; gain=1.55)\n",
        "act_fn = Mish() #nn.ReLU(inplace=True)\n",
        "\n",
        "class Flatten(Module):\n",
        "    def forward(self, x): return x.view(x.size(0), -1)\n",
        "\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
        "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)\n",
        "\n",
        "def noop(x): return x\n",
        "\n",
        "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
        "    if act: layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1):\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        layers  = [conv_layer(ni, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
        "        ] if expansion == 1 else [\n",
        "                   conv_layer(ni, nh, 1),\n",
        "                   conv_layer(nh, nh, 3, stride=stride),\n",
        "                   conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
        "        ]\n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        # TODO: check whether act=True works better\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False)\n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x): return act_fn(self.convs(x) + self.idconv(self.pool(x)))\n",
        "\n",
        "def filt_sz(recep): return min(64, 2**math.floor(math.log2(recep*0.75)))\n",
        "\n",
        "class MXResNet(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n",
        "        stem = []\n",
        "        sizes = [c_in,32,64,64]  #modified per Grankin\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n",
        "            #nf = filt_sz(c_in*9)\n",
        "            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n",
        "            #c_in = nf\n",
        "\n",
        "        block_szs = [64//expansion,64,128,256,512]\n",
        "        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n",
        "                  for i,l in enumerate(layers)]\n",
        "        super().__init__(\n",
        "            *stem,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            *blocks,\n",
        "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "            nn.Linear(block_szs[-1]*expansion, c_out),\n",
        "        )\n",
        "        init_cnn(self)\n",
        "\n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
        "        return nn.Sequential(\n",
        "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
        "              for i in range(blocks)])\n",
        "\n",
        "def mxresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n",
        "    model = MXResNet(expansion, n_layers, **kwargs)\n",
        "    if pretrained: \n",
        "        #model.load_state_dict(model_zoo.load_url(model_urls[name]))\n",
        "        print(\"No pretrained yet for MXResNet\")\n",
        "    return model\n",
        "\n",
        "me = sys.modules[__name__]\n",
        "for n,e,l in [\n",
        "    [ 18 , 1, [2,2,2 ,2] ],\n",
        "    [ 34 , 1, [3,4,6 ,3] ],\n",
        "    [ 50 , 4, [3,4,6 ,3] ],\n",
        "    [ 101, 4, [3,4,23,3] ],\n",
        "    [ 152, 4, [3,8,36,3] ],\n",
        "]:\n",
        "    name = f'mxresnet{n}'\n",
        "    setattr(me, name, partial(mxresnet, expansion=e, n_layers=l, name=name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mish activation loaded...\n",
            "Mish activation loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3kefDgEeKb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
        "\n",
        "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
        "#https://arxiv.org/abs/1908.08681v1\n",
        "#implemented for PyTorch / FastAI by lessw2020 \n",
        "#github: https://github.com/lessw2020/mish\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x *( torch.tanh(F.softplus(x)))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemWTu8NeWfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools as it\n",
        "from torch.optim import Optimizer, Adam\n",
        "\n",
        "class Lookahead(Optimizer):\n",
        "    def __init__(self, base_optimizer,alpha=0.5, k=6):\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        self.optimizer = base_optimizer\n",
        "        self.param_groups = self.optimizer.param_groups\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "        for group in self.param_groups:\n",
        "            group[\"step_counter\"] = 0\n",
        "        self.slow_weights = [[p.clone().detach() for p in group['params']]\n",
        "                                for group in self.param_groups]\n",
        "\n",
        "        for w in it.chain(*self.slow_weights):\n",
        "            w.requires_grad = False\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "        loss = self.optimizer.step()\n",
        "        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n",
        "            group['step_counter'] += 1\n",
        "            if group['step_counter'] % self.k != 0:\n",
        "                continue\n",
        "            for p,q in zip(group['params'],slow_weights):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                q.data.add_(self.alpha,p.data - q.data)\n",
        "                p.data.copy_(q.data)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-NkvL2Sdyv",
        "colab_type": "code",
        "outputId": "63c9f3ad-37ba-4792-adc9-b9bfecd1018b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "res = []\n",
        "num_epoch=5\n",
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(20, max_lr=3e-3)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.084373</td>\n",
              "      <td>2.096703</td>\n",
              "      <td>0.278000</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.879687</td>\n",
              "      <td>2.158034</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.739452</td>\n",
              "      <td>1.858424</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.653582</td>\n",
              "      <td>1.740463</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.534283</td>\n",
              "      <td>1.861979</td>\n",
              "      <td>0.452000</td>\n",
              "      <td>0.884000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.416016</td>\n",
              "      <td>1.489798</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.946000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.323618</td>\n",
              "      <td>1.396875</td>\n",
              "      <td>0.642000</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.264390</td>\n",
              "      <td>1.396464</td>\n",
              "      <td>0.636000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.194979</td>\n",
              "      <td>1.218947</td>\n",
              "      <td>0.698000</td>\n",
              "      <td>0.948000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.102362</td>\n",
              "      <td>1.139388</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.059779</td>\n",
              "      <td>1.063944</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.007487</td>\n",
              "      <td>1.055259</td>\n",
              "      <td>0.776000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.946365</td>\n",
              "      <td>1.032367</td>\n",
              "      <td>0.796000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.917979</td>\n",
              "      <td>0.927734</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.884780</td>\n",
              "      <td>0.933966</td>\n",
              "      <td>0.814000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.834159</td>\n",
              "      <td>0.883575</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.799462</td>\n",
              "      <td>0.878927</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.787120</td>\n",
              "      <td>0.858806</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.773306</td>\n",
              "      <td>0.859585</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.757912</td>\n",
              "      <td>0.868731</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZyW388bkDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJX7Ylxblox",
        "colab_type": "code",
        "outputId": "8964cf15-da89-4357-c9eb-87c672b46b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(20, max_lr=3e-3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.064888</td>\n",
              "      <td>1.982225</td>\n",
              "      <td>0.316000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.866454</td>\n",
              "      <td>2.302265</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.736936</td>\n",
              "      <td>2.342365</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.615955</td>\n",
              "      <td>1.690154</td>\n",
              "      <td>0.472000</td>\n",
              "      <td>0.904000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.522823</td>\n",
              "      <td>1.616593</td>\n",
              "      <td>0.546000</td>\n",
              "      <td>0.926000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.424253</td>\n",
              "      <td>1.550730</td>\n",
              "      <td>0.570000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.335092</td>\n",
              "      <td>1.368072</td>\n",
              "      <td>0.644000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.252069</td>\n",
              "      <td>1.342005</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.958000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.181628</td>\n",
              "      <td>1.234345</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.958000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.110938</td>\n",
              "      <td>1.143214</td>\n",
              "      <td>0.724000</td>\n",
              "      <td>0.972000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.064149</td>\n",
              "      <td>1.060943</td>\n",
              "      <td>0.762000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.022530</td>\n",
              "      <td>1.039679</td>\n",
              "      <td>0.766000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.956009</td>\n",
              "      <td>1.004417</td>\n",
              "      <td>0.772000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.927970</td>\n",
              "      <td>0.930110</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.924059</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.836351</td>\n",
              "      <td>0.904653</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.808626</td>\n",
              "      <td>0.900705</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.781184</td>\n",
              "      <td>0.886015</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.766834</td>\n",
              "      <td>0.889178</td>\n",
              "      <td>0.836000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.762658</td>\n",
              "      <td>0.881614</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ER6N0lcbmZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cmH0cLbnPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "b49294d3-40da-4105-d0fc-e26b2277c462"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(20, max_lr=3e-3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.077032</td>\n",
              "      <td>2.050649</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.861813</td>\n",
              "      <td>1.931837</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.750800</td>\n",
              "      <td>2.063384</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.635669</td>\n",
              "      <td>1.880313</td>\n",
              "      <td>0.432000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.558453</td>\n",
              "      <td>1.814712</td>\n",
              "      <td>0.468000</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.442231</td>\n",
              "      <td>1.510067</td>\n",
              "      <td>0.556000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.351647</td>\n",
              "      <td>1.507930</td>\n",
              "      <td>0.616000</td>\n",
              "      <td>0.926000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.263998</td>\n",
              "      <td>1.507027</td>\n",
              "      <td>0.578000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.197337</td>\n",
              "      <td>1.239119</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.133025</td>\n",
              "      <td>1.191332</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.067710</td>\n",
              "      <td>1.167853</td>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.027800</td>\n",
              "      <td>1.081528</td>\n",
              "      <td>0.752000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.974346</td>\n",
              "      <td>1.025155</td>\n",
              "      <td>0.782000</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.921237</td>\n",
              "      <td>1.063288</td>\n",
              "      <td>0.754000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.883930</td>\n",
              "      <td>0.942115</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.849780</td>\n",
              "      <td>0.974913</td>\n",
              "      <td>0.812000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.815583</td>\n",
              "      <td>0.920651</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.797373</td>\n",
              "      <td>0.900191</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.772470</td>\n",
              "      <td>0.893985</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.766479</td>\n",
              "      <td>0.889032</td>\n",
              "      <td>0.842000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHJVXRQboCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfuhPs_dboyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "20c51b36-4fbc-4c54-9f1f-7f0654222228"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(20, max_lr=3e-3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.050308</td>\n",
              "      <td>2.015106</td>\n",
              "      <td>0.316000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.856873</td>\n",
              "      <td>2.004164</td>\n",
              "      <td>0.368000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.737028</td>\n",
              "      <td>3.149825</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.762000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.653702</td>\n",
              "      <td>2.115754</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.538797</td>\n",
              "      <td>1.528147</td>\n",
              "      <td>0.548000</td>\n",
              "      <td>0.926000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.433369</td>\n",
              "      <td>1.517626</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.335768</td>\n",
              "      <td>1.557893</td>\n",
              "      <td>0.584000</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.244490</td>\n",
              "      <td>1.243512</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.184286</td>\n",
              "      <td>1.143195</td>\n",
              "      <td>0.726000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.122705</td>\n",
              "      <td>1.132270</td>\n",
              "      <td>0.728000</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.082549</td>\n",
              "      <td>1.138590</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.016606</td>\n",
              "      <td>1.012671</td>\n",
              "      <td>0.774000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.969714</td>\n",
              "      <td>0.982152</td>\n",
              "      <td>0.802000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.919391</td>\n",
              "      <td>0.905659</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.883871</td>\n",
              "      <td>0.966984</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.839568</td>\n",
              "      <td>0.902122</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.824235</td>\n",
              "      <td>0.888983</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.788066</td>\n",
              "      <td>0.869600</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.773370</td>\n",
              "      <td>0.873643</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.770957</td>\n",
              "      <td>0.867243</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.988000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zluKwmebpWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTtJywE8bq5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "90bf8fd5-5723-477a-ee93-22394f767195"
      },
      "source": [
        "learn = Learner(data, mxresnet50(c_out=10), wd=1e-2, \n",
        "               metrics=[accuracy, top_k_accuracy],\n",
        "               bn_wd=False, true_wd=True,\n",
        "               loss_func=LabelSmoothingCrossEntropy())\n",
        "\n",
        "learn.fit_one_cycle(20, max_lr=3e-3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.086531</td>\n",
              "      <td>2.026362</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.908724</td>\n",
              "      <td>1.948479</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.760613</td>\n",
              "      <td>1.968992</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.878000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.653947</td>\n",
              "      <td>1.732773</td>\n",
              "      <td>0.482000</td>\n",
              "      <td>0.888000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.537726</td>\n",
              "      <td>1.741035</td>\n",
              "      <td>0.496000</td>\n",
              "      <td>0.914000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.456567</td>\n",
              "      <td>1.665006</td>\n",
              "      <td>0.524000</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.322566</td>\n",
              "      <td>1.589853</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.262224</td>\n",
              "      <td>1.857657</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.918000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.202850</td>\n",
              "      <td>1.354937</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.117390</td>\n",
              "      <td>1.099138</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.065798</td>\n",
              "      <td>1.099686</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.029061</td>\n",
              "      <td>1.076238</td>\n",
              "      <td>0.762000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.973975</td>\n",
              "      <td>1.021465</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.921500</td>\n",
              "      <td>0.917330</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.883577</td>\n",
              "      <td>0.911173</td>\n",
              "      <td>0.816000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.845684</td>\n",
              "      <td>0.892317</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.818368</td>\n",
              "      <td>0.887420</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.793966</td>\n",
              "      <td>0.869981</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.765967</td>\n",
              "      <td>0.872304</td>\n",
              "      <td>0.836000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.763253</td>\n",
              "      <td>0.864975</td>\n",
              "      <td>0.848000</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>02:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkPOpr9Kbrf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, topk = learn.validate()\n",
        "res.append(acc.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnABPBXUiwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d452683d-336b-45fb-9af4-dc010f3c8ea2"
      },
      "source": [
        "np.mean(res)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83760005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_vjMWEiL7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73df109d-d1f1-4dbd-95b8-14947c90c1f9"
      },
      "source": [
        "np.std(res)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0070880107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hArOffsgiNP-",
        "colab_type": "code",
        "outputId": "8b8b532b-9e10-4e92-c606-b4a72060f56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(0.838, dtype=float32),\n",
              " array(0.832, dtype=float32),\n",
              " array(0.842, dtype=float32),\n",
              " array(0.828, dtype=float32),\n",
              " array(0.848, dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OU10gtbiumN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}