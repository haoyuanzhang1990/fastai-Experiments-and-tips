{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Sets in v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP2yQVJYy7A",
        "colab_type": "code",
        "outputId": "13b2b1cb-18d9-425c-8361-3435b30f1ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip3 install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 23kB/s \n",
            "\u001b[?25hCollecting torchvision===0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.2.0) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.0) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision===0.4.0) (0.46)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.3.0+cu100\n",
            "    Uninstalling torch-1.3.0+cu100:\n",
            "      Successfully uninstalled torch-1.3.0+cu100\n",
            "  Found existing installation: torchvision 0.4.1+cu100\n",
            "    Uninstalling torchvision-0.4.1+cu100:\n",
            "      Successfully uninstalled torchvision-0.4.1+cu100\n",
            "Successfully installed torch-1.2.0 torchvision-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkPccEamY6Gl",
        "colab_type": "code",
        "outputId": "9b1b4dfa-0a99-4485-d55c-fb1ab4f1c33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastai_dev > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/fastai/fastai_dev /tmp/pip-req-build-krat64vk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h666vlweZy2l",
        "colab_type": "text"
      },
      "source": [
        "# Tabular + Test Sets\n",
        "\n",
        "This notebook will explore tabular data and adding test sets, labeled and non-labelled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9EA5KMkAbfo",
        "colab_type": "text"
      },
      "source": [
        "First let's import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8NkvO04aFTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.data.all import *\n",
        "from fastai2.tabular.core import *\n",
        "from fastai2.tabular.model import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1til4MWAfNO",
        "colab_type": "text"
      },
      "source": [
        "Then we'll read in the `ADULT_SAMPLE` dataframe and section out a part of it as a test dataframe (`df_test`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYWFhfNZ4l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')\n",
        "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYL5Z0R_AlYn",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll define our variables, pre-processers, and our splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12POtH9ZaEvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [Categorify, FillMissing, Normalize]\n",
        "splits = RandomSplitter()(range_of(df_main))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Sep7PRAqzg",
        "colab_type": "text"
      },
      "source": [
        "And now we will create two `DataBunch` objects. One for training with, the other with our test set (which can be labelled now!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5L5SaKaSRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=\"salary\", splits=splits)\n",
        "to_test = TabularPandas(df_test, procs, cat_names, cont_names, y_names=\"salary\")\n",
        "# if splits is blank it will default as split_none() (from v1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgT_nwBGB73J",
        "colab_type": "text"
      },
      "source": [
        "We want to set our train's shuffle to `False` as this is our \"test\" DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkUvbroF797",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dl = TabDataLoader(to_test, bs=128, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli0eco8dRx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = to.databunch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uyxrfL0CFgW",
        "colab_type": "text"
      },
      "source": [
        "Now we will make a tabular model (I copied the code as its not *quite* exported yet in the library)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6trHMeV1bqed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.tabular.core import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_nnf-MlbzR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TabularModel(Module):\n",
        "    \"Basic model for tabular data.\"\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=None, embed_p=0., y_range=None, use_bn=True, bn_final=False):\n",
        "        ps = ifnone(ps, [0]*len(layers))\n",
        "        if not is_listy(ps): ps = [ps]*len(layers)\n",
        "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(embed_p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
        "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
        "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
        "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
        "        _layers = [BnDropLin(sizes[i], sizes[i+1], bn=use_bn and i!=0, p=p, act=a)\n",
        "                       for i,(p,a) in enumerate(zip([0.]+ps,actns))]\n",
        "        if bn_final: _layers.append(nn.BatchNorm1d(sizes[-1]))\n",
        "        self.layers = nn.Sequential(*_layers)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        if self.n_emb != 0:\n",
        "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
        "            x = torch.cat(x, 1)\n",
        "            x = self.emb_drop(x)\n",
        "        if self.n_cont != 0:\n",
        "            x_cont = self.bn_cont(x_cont)\n",
        "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
        "        x = self.layers(x)\n",
        "        if self.y_range is not None:\n",
        "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMUrWqA0b1tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb_sz(to, sz_dict=None):\n",
        "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
        "    return [_one_emb_sz(to.procs.classes, n, sz_dict) for n in to.cat_names]\n",
        "\n",
        "def _one_emb_sz(classes, n, sz_dict=None):\n",
        "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
        "    sz_dict = ifnone(sz_dict, {})\n",
        "    n_cat = len(classes[n])\n",
        "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
        "    return n_cat,sz\n",
        "\n",
        "def emb_sz_rule(n_cat): \n",
        "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
        "    return min(600, round(1.6 * n_cat**0.56))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgCNZv3Nbej2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TabularModel(get_emb_sz(to), len(to.cont_names), 2, [200,100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Nydz5pcFLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.learner import *\n",
        "from fastai2.metrics import *\n",
        "from fastai2.optimizer import *\n",
        "from fastai2.callback.schedule import fit_one_cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4aGUWKIbqDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
        "learn = Learner(dbunch, model, CrossEntropyLossFlat(), opt_func=opt_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65SP69Kb_Zl",
        "colab_type": "code",
        "outputId": "ef0bf453-e627-463a-8c08-a87f421cab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#5) [0,0.41459986567497253,0.3640693128108978,0.8270000219345093,00:13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXbTdx95CMCq",
        "colab_type": "text"
      },
      "source": [
        "Now that we've trained, let's look at how to do `get_preds` and `validate` with our test data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpHhFmpECRPS",
        "colab_type": "text"
      },
      "source": [
        "We can pass in our `dbunch_test`'s dataloader (either `train_dl` or `valid_dl`) in the `dl` argument for both and it will operate on them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSg6aGLK3PUI",
        "colab_type": "code",
        "outputId": "612f91a8-f0c5-4b42-982a-c830280351d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.validate(dl=test_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3573826849460602, 0.8347591161727905]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqC5_kRO3b4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJHgnQCZCca0",
        "colab_type": "text"
      },
      "source": [
        "Just to make sure, let's verify our `preds` and `validate()` match up!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohm8wGq3hRH",
        "colab_type": "code",
        "outputId": "b2b1e47b-6878-46c5-c5a4-5c52b091aa85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3941, 0.6059],\n",
              "         [0.7603, 0.2397],\n",
              "         [0.9382, 0.0618],\n",
              "         ...,\n",
              "         [0.4261, 0.5739],\n",
              "         [0.6419, 0.3581],\n",
              "         [0.6023, 0.3977]]), tensor([0, 0, 0,  ..., 1, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNlohvSN3oRA",
        "colab_type": "code",
        "outputId": "091109dc-25bc-49af-9ceb-f47bcb368643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(preds[0], preds[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8348)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aUgBwTACmaW",
        "colab_type": "text"
      },
      "source": [
        "And they do perfectly! "
      ]
    }
  ]
}