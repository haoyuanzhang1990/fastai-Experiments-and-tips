{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Sets in v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP2yQVJYy7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install typeguard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkPccEamY6Gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee7976df-2058-4d57-c5a0-6cfa60f8e057"
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastai_dev > /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/fastai/fastai_dev /tmp/pip-req-build-wugx8srw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h666vlweZy2l",
        "colab_type": "text"
      },
      "source": [
        "# Tabular + Test Sets\n",
        "\n",
        "This notebook will explore tabular data and adding test sets, labeled and non-labelled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9EA5KMkAbfo",
        "colab_type": "text"
      },
      "source": [
        "First let's import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8NkvO04aFTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.data.all import *\n",
        "from fastai2.tabular.core import *\n",
        "from fastai2.tabular.model import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1til4MWAfNO",
        "colab_type": "text"
      },
      "source": [
        "Then we'll read in the `ADULT_SAMPLE` dataframe and section out a part of it as a test dataframe (`df_test`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYWFhfNZ4l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')\n",
        "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYL5Z0R_AlYn",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll define our variables, pre-processers, and our splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12POtH9ZaEvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [Categorify, FillMissing, Normalize]\n",
        "splits = RandomSplitter()(range_of(df_main))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Sep7PRAqzg",
        "colab_type": "text"
      },
      "source": [
        "And now we will create two `DataBunch` objects. One for training with, the other with our test set (which can be labelled now!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5L5SaKaSRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=\"salary\", splits=splits)\n",
        "to_test = TabularPandas(df_test, procs, cat_names, cont_names, y_names=\"salary\")\n",
        "# if splits is blank it will default as split_none() (from v1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgT_nwBGB73J",
        "colab_type": "text"
      },
      "source": [
        "We want to set our train's shuffle to `False` as this is our \"test\" DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkUvbroF797",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dl = TabDataLoader(to_test, bs=128, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli0eco8dRx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbuch = to.databunch()\n",
        "dbunch_test = to_test.databunch(shuffle_train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uyxrfL0CFgW",
        "colab_type": "text"
      },
      "source": [
        "Now we will make a tabular model (I copied the code as its not *quite* exported yet in the library)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6trHMeV1bqed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.tabular.core import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_nnf-MlbzR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TabularModel(Module):\n",
        "    \"Basic model for tabular data.\"\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=None, embed_p=0., y_range=None, use_bn=True, bn_final=False):\n",
        "        ps = ifnone(ps, [0]*len(layers))\n",
        "        if not is_listy(ps): ps = [ps]*len(layers)\n",
        "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(embed_p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
        "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
        "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
        "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
        "        _layers = [BnDropLin(sizes[i], sizes[i+1], bn=use_bn and i!=0, p=p, act=a)\n",
        "                       for i,(p,a) in enumerate(zip([0.]+ps,actns))]\n",
        "        if bn_final: _layers.append(nn.BatchNorm1d(sizes[-1]))\n",
        "        self.layers = nn.Sequential(*_layers)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        if self.n_emb != 0:\n",
        "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
        "            x = torch.cat(x, 1)\n",
        "            x = self.emb_drop(x)\n",
        "        if self.n_cont != 0:\n",
        "            x_cont = self.bn_cont(x_cont)\n",
        "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
        "        x = self.layers(x)\n",
        "        if self.y_range is not None:\n",
        "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMUrWqA0b1tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb_sz(to, sz_dict=None):\n",
        "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
        "    return [_one_emb_sz(to.procs.classes, n, sz_dict) for n in to.cat_names]\n",
        "\n",
        "def _one_emb_sz(classes, n, sz_dict=None):\n",
        "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
        "    sz_dict = ifnone(sz_dict, {})\n",
        "    n_cat = len(classes[n])\n",
        "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
        "    return n_cat,sz\n",
        "\n",
        "def emb_sz_rule(n_cat): \n",
        "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
        "    return min(600, round(1.6 * n_cat**0.56))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgCNZv3Nbej2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TabularModel(get_emb_sz(to), len(to.cont_names), 2, [200,100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Nydz5pcFLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.learner import *\n",
        "from fastai2.metrics import *\n",
        "from fastai2.optimizer import *\n",
        "from fastai2.callback.schedule import fit_one_cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4aGUWKIbqDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
        "learn = Learner(dbch, model, CrossEntropyLossFlat(), opt_func=opt_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65SP69Kb_Zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220349d4-52ec-49a6-cbe9-d10a9fb0111f"
      },
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#5) [0,0.4465666711330414,0.3819335103034973,0.8180000185966492,00:13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXbTdx95CMCq",
        "colab_type": "text"
      },
      "source": [
        "Now that we've trained, let's look at how to do `get_preds` and `validate` with our test data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpHhFmpECRPS",
        "colab_type": "text"
      },
      "source": [
        "We can pass in our `dbunch_test`'s dataloader (either `train_dl` or `valid_dl`) in the `dl` argument for both and it will operate on them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSg6aGLK3PUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7be0b938-ae45-4488-8d0f-3506dcc011dd"
      },
      "source": [
        "learn.validate(dl=test_dl)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35957658290863037, 0.8312131762504578]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqC5_kRO3b4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = learn.get_preds(dl=dbch_test.train_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJHgnQCZCca0",
        "colab_type": "text"
      },
      "source": [
        "Just to make sure, let's verify our `preds` and `validate()` match up!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohm8wGq3hRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "70fc6b70-754e-4d30-fda8-7bcff68f14fa"
      },
      "source": [
        "preds"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5105, 0.4895],\n",
              "         [0.7767, 0.2233],\n",
              "         [0.9480, 0.0520],\n",
              "         ...,\n",
              "         [0.5167, 0.4833],\n",
              "         [0.7386, 0.2614],\n",
              "         [0.6656, 0.3344]]), tensor([0, 0, 0,  ..., 1, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNlohvSN3oRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50fec995-8da1-4829-d39e-0dc904d40f3a"
      },
      "source": [
        "accuracy(preds[0], preds[1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aUgBwTACmaW",
        "colab_type": "text"
      },
      "source": [
        "And they do perfectly! "
      ]
    }
  ]
}